<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to ARIMA Models Using R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Laura Rose" />
    <meta name="date" content="2022-04-19" />
    <script src="libs/header-attrs-2.9/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to ARIMA Models Using R
### Laura Rose
### April 19, 2022

---




## Intro to ARIMA Models
- ARIMA models are one of the most common univariate time series forecasting methods.

--

- ARIMA stands for **A**uto**R**egressive **I**ntegrated **M**oving **A**verage.

--

- We will explore each part of the ARIMA model in detail before moving on to its implementation in R.

---

## For Further Reading
- Hyndman, R.J., &amp; Athanasopoulos, G. (2021) *Forecasting: principles and practice*, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on March 3, 2022.
- Brooks, C. (2008). *Introductory Econometrics for Finance*, 2nd edition, Cambridge University Press: Cambridge, United Kingdom.

---

## Stationarity
- A time series is said to be *strictly stationary* if the distribution of the observations does not change across time.

--

- However, strict stationarity is not always necessary to model a time series. We often reference *weak stationarity* in our analysis.

--

- `\(E(y_{t}) = \mu\)` (constant mean)

--

- `\(E[(y_{t} - \mu)(y_{t} - \mu)] = \sigma^2 &lt; \infty\)` (constant variance)

--

- `\(E[(y_{t_{k}} - \mu)(y_{t_{k'}} - \mu)] = \gamma_{t_{k}-t_{k'}} \space \forall \space t_{k}, t_{k'}\)` (constant autocovariance)

--
  - When `\(k = k'\)`, the autocovariance is the variance.
  
--

- The autocovariance is not particularly useful since it is scale-dependent. Therefore, we often normalize the autocovariance by dividing by the variance.

--

- This is called the *autocorrelation*, and this measure has the usefulness of being bounded between `\(\pm1\)`

---

## White Noise Process

- A *white noise process* is a special case of a stationary process.

--

`$$E(y_{t}) = 0$$`

--

`$$E[(y_{t} - \mu)(y_{t} - \mu)] = \sigma^2$$`

--

`$$\gamma_{k-k'} = \left\{\begin{aligned}
&amp;\sigma^2 &amp;&amp;if \space k = k'\\
&amp;0 &amp;&amp; otherwise
\end{aligned}
\right.$$`

--

- *Note that some definitions of a white noise process indicate a nonzero mean is permissible.*

---

## Random Walk 

- A *random walk* model is often used to denote a nonstationary time series.

--

- `\(y_{t} = y_{t-1} + \varepsilon_{t}\)` or

--

- `\(y_{t} = c + y_{t-1} + \varepsilon_{t}\)` (random walk w/drift)
  - `\(c\)` is the mean of the changes between sequential observations.
  - If `\(c &gt; 0\)`, the mean change will tend towards an increase in `\(y_{t}\)`, and vice versa for negative values of `\(c\)`. 
  
--

- Random walk series often have long period of increases or decreases accompanied with sudden changes in direction.

---

## What to Do If Data is Nonstationary?
- So what happens if we find our data violates any of the (weak) stationarity conditions?

--

- Note that data with trend or seasonality is not stationary, but data with cyclic behavior (i.e., business or other cycles which are not of fixed length) can be stationary.

--

- Differencing the series is a common way to deal with nonstationarity resulting from autocorrelation. 

--

  - The difference of a value with the previous value is called *first-order differencing*: `\(y'_{t} = y_{t} - y_{t-1}\)`.
  - Note that for a random walk model, `\(y'_{t} = \varepsilon_{t}\)`. 
  - Thus, this series is now stationary given the properties of `\(\varepsilon_{t}\)`.
  
--

  - Sometimes this is not enough to make the series stationary, so we take the difference of the differences.

--

`$$\begin{align*}
  y''_{t}  &amp;=  y'_{t}  - y'_{t - 1} \\
           &amp;= (y_t - y_{t-1}) - (y_{t-1}-y_{t-2})\\
           &amp;= y_t - 2y_{t-1} +y_{t-2}
\end{align*}$$`

---

## What to Do if Data is Nonstationary, cont.

- If we notice a seasonal pattern, we can take a seasonal difference: `\(y'_{t} = y_{t} - y_{t-m}\)`, where `\(m\)` is the seasonal period. 

--

- If the data looks like it may require both first-differencing and seasonal differencing, it's better to take the seasonal difference first.

--

- This is especially true in the case of strong seasonality, since sometimes taking a seasonal difference is enough to make the series stationary.

--

- However, taking a first difference will not get rid of seasonal stationarity.

--

- Always use as few differences as possible, since too much differencing can induce patterns in the series that are not actually there.

--

- If the variance appears nonconstant across time, a logarithmic transformation can be used to stabilize.

---

## How to Test for Nonstationarity

- There are both formal and nonformal ways to examine the time series.

--

- We should always start by plotting the time series (line plot is generally best), since often nonstationarity and nonconstant variance are visible to the human eye.

--

- If we suspect nonstationarity, we should plot the autocorrelation function (ACF) and check for observations outside of the 95% confidence interval around 0. We particularly want to examine how quickly these autocorrelations drop to 0.

--

- To formally test for stationarity, we conduct a *unit root test*.

--

- Taking a cue from Dr. Hyndman, we will use the KPSS test, but other tests are available (ADF and PP tests).

--

- A *unit root* implies that the data is essentially a function of its lag(s) where the coefficient equals 1, plus some noise. (There are some variations on this, but we will skip discussion for the sake of simplicity.)
  - In more formal terms, the root of the characteristic equation equals 1.

---

## An Example of Checking for Stationarity

.pull-left[

```r
data(BJsales)
date_sequence &lt;- seq(as.Date("1955-01-01"), 
by = "month", length.out = 150)
Sales_tsib &lt;- tsibble(Month = yearmonth(date_sequence), 
Sales = BJsales, index = Month)
autoplot(Sales_tsib)
```
]

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-1-1.png" width="504" /&gt;
]

---

## Checking the ACF

.pull-left[

```r
Sales_tsib %&gt;% ACF() %&gt;% autoplot()
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-2-1.png" width="504" /&gt;
]

---

## Testing for a Unit Root 


```r
uroot_table &lt;- Sales_tsib %&gt;% 
features(Sales, unitroot_kpss) %&gt;% 
bind_cols(Sales_tsib %&gt;%
features(Sales, unitroot_ndiffs)) %&gt;% 
bind_cols(Sales_tsib %&gt;% 
features(Sales, unitroot_nsdiffs))
knitr::kable(uroot_table, format = "html",
digits = 2, align = "c")
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; kpss_stat &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; kpss_pvalue &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; ndiffs &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; nsdiffs &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 2.62 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.01 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

- We clearly have a unit root (we reject the null hypothesis of stationarity), but it doesn't look like we will need to take a seasonal difference.

---

## Backshift Notation

- This notation is a (hopefully!) helpful shorthand to describe lags of variables for easier manipulation. Think of `\(B\)` as "backshift."

--

- `\(By_{t} = y_{t-1}\)`

--

- By extension, `\(B(By_{t}) = B^2y_{t} = y_{t-2}\)`, etc.

--

- Same quarter last year would be `\(B^4y_{t} = y_{t-4}\)`

--

- We can also use the backshift operator to describe differencing.
`$$y' = y_{t} - y_{t-1} = y_{t} - By_{t} = (1-B)y_{t}$$`
- We can treat the expressions in `\(B\)` like polynomials and solve for roots (thus the unit root concept).
  
--

`$$\begin{align*}
y'' &amp;= (y_{t} - y_{t-1}) - (y_{t-1} - y_{t-2})\\ 
    &amp;= y_{t} - By_{t} - By_{t} + B^2y_{t}\\ 
    &amp;= y_{t} - 2By_{t} + B^2y_{t}\\ 
    &amp;= (B-1)^2y_{t}\\ 
    &amp;= (1-B)^2y_{t}
\end{align*}$$`
  
---

## Autoregressive (AR) Models

- With an AR model, we forecast a time series using a linear combination of prior values of the series. In other words, `\(y_{t}\)` is regressed on itself.

--

- An autoregressive model of order `\(p\)` (an `\(AR(p)\)`) model is written as follows, where `\(\varepsilon_{t}\)` is a white noise process:

--

`$$y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + ... + \phi_{p}y_{t-p} + \varepsilon_{t}$$`
--

- `\(AR(1)\)` models as they relate to previous models we've discussed:
  - when `\(\phi_{1} = 0\)` and `\(c = 0\)`, `\(y_{t}\)` is white noise
  - when `\(\phi_{1} = 1\)` and `\(c = 0\)`, `\(y_{t}\)` is a random walk process
  - when `\(\phi_{1} = 1\)` and `\(c \neq 0\)`, `\(y_{t}\)` is a random walk with drift process
  - when `\(\phi_{1} &lt; 0\)`, `\(y_{t}\)` tends to fluctuate around the mean

--

- `\(AR(p)\)` models, stationary data, and constraints:
  - `\(AR(1)\)` model: `\(-1 &lt; \phi_{1} &lt; 1\)`
  - `\(AR(2)\)` model: `\(-1 &lt; \phi_{2} &lt; 1\)`, `\(\phi_{1} + \phi_{2} &lt; 1\)`, `\(\phi_{1} - \phi_{2} &lt; 1\)`

--

- These restrictions, as well as restrictions for higher orders of `\(p\)`, are handled automatically in the `fable` package.

---

## An Example of AR(1) Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(1, 0, 0),
ar = 0.7), n = 300) %&gt;% as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-3-1.png" width="504" /&gt;
]

---

## Another Example of AR(1)&lt;sup&gt;*&lt;/sup&gt; Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(1, 1, 0),
ar = 0.7), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-4-1.png" width="504" /&gt;
]

.footnote[[*]&lt;small&gt;This is technically not an AR(1) model,&lt;br&gt; but rather an ARIMA(1,1,0).&lt;br&gt; We can see the difference in a stationary versus nonstationary series.&lt;/small&gt;]

---

## An Example of an AR(2) Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(2, 0, 0),
ar = c(1.3, -0.6)), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-5-1.png" width="504" /&gt;
]

---

## Another Example of an AR(2)&lt;sup&gt;*&lt;/sup&gt; Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(2, 1, 0),
ar = c(0.6, 0.3)), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-6-1.png" width="504" /&gt;
]

.footnote[[*]&lt;small&gt;This is technically not an AR(2) model,&lt;br&gt; but rather an ARIMA(2,1,0).&lt;br&gt; We can see the difference in a stationary versus nonstationary series.&lt;/small&gt;]

---

## Moving Average (MA) Models

- The "MA" portion of ARIMA refers to a *moving average* model, where `\(y_{t}\)` is regressed on previous forecast errors. 

--

- `\(y_{t} = c + \varepsilon_{t} + \theta_{1}\varepsilon_{t-1} + ... + \theta_{q}\varepsilon_{t-q}\)`

--

- This is called an `\(MA(q)\)` model, or a moving average model of order `\(q\)`.

--

- Since we don't observe `\(\varepsilon_{t}\)` (the forecast errors are a proxy for `\(\varepsilon_{t}\)`), these models aren't a regression in the sense we normally consider.

--

- `\(\varepsilon_{t}\)` is a white noise process with mean 0 and variance/standard deviation of 1.

---

## An Example of an MA(1) Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(0, 0, 1),
ma = 0.5), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-7-1.png" width="504" /&gt;
]

---

## An Example of an MA(2) Process

.pull-left[


```r
set.seed(5)
arima.sim(list(order = c(0, 0, 2),
ma = c(0.6, 0.3)), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```

]

--

.pull-right[

&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-8-1.png" width="504" /&gt;

]

---

## Invertibility

- We can express any *stationary* `\(AR(p)\)` model as an `\(MA(\infty)\)` model, using backwards substitution. Below is an example for an `\(AR(1)\)` model.

--

`$$\begin{align*}
y_{t} &amp;= \phi_{1}y_{t-1} + \varepsilon_{t}\\ 
    &amp;= \phi_{1}(\phi_{1}y_{t-2} + \varepsilon_{t-1}) + \varepsilon_{t}\\ 
    &amp;= \phi_{1}^2y_{t-2} + \phi_{1}\varepsilon_{t-1} + \varepsilon_{t}\\ 
    &amp;= \phi_{1}^2(\phi_{1}y_{t-3} + \varepsilon_{t-2}) + \phi_{1}\varepsilon_{t-1} + \varepsilon_{t}\\ 
    &amp;= \phi_{1}^3y_{t-3} + \phi_{1}^2\varepsilon_{t-2} + \phi_{1}\varepsilon_{t-1} + \varepsilon_{t}
\end{align*}$$`

--

- When `\(|\phi_{1}| &lt; 1\)`, `\(\phi_{1}^k\)` will approach zero as `\(k \to \infty\)`.
  - `\(y_{t} = \varepsilon_{t} + \phi_{1}\varepsilon_{t-1} + \phi_{1}^2\varepsilon_{t-2} + ...\)`
  
---

## Invertibility, cont.

- An `\(MA(q)\)` process can be inverted to an `\(AR(\infty)\)` process if we impose constraints on the parameters. These constraints are similar to those we saw for `\(AR(p)\)` processes.

--

  - The current forecast error is a function of infinite past and current observations of the time series, as seen for an `\(MA(1)\)` model.
  - `\(\varepsilon_{t} = \sum_{i=0}^\infty(-\theta_{1})^iy_{t-i}\)`

--

  - When `\(|\theta_1| &lt; 1\)`, the impact of observations on the current error declines as we go back in time.
  - If `\(|\theta_1| &gt; 1\)` or `\(|\theta_1| = 1\)`, the distant past observations have more or equal weight to the recent observations, and neither situation makes sense.
  
--

  - So an `\(MA(1)\)` process is invertible when `\(|\theta_1| &lt; 1\)`.

--

  - Similar to an `\(AR(2)\)` process, an `\(MA(2)\)` process is invertible when `\(|\theta_2| &lt; 1\)`, `\(\theta_1 + \theta_2 &gt; -1\)`, `\(\theta_1 - \theta_2 &lt; 1\)`.
  - Other more complex constraints hold for higher orders of `\(q\)`, and the `fable` package handles these.

---

## Putting It All Together

- So far we've discussed `\(AR\)` models, `\(MA\)` models, and differencing time series to ensure stationarity (*I* = *Integration*).

--

- We refer to an `\(ARIMA(p, d, q)\)` model, where `\(p\)` = order of the `\(AR\)` part, `\(d\)` = degree of differencing, and `\(q\)` = order of `\(MA\)` part.

--

`$$y'_t = c + \phi_1y'_{t-1} + ... + \phi_py'_{t-p} + \theta_1\varepsilon_{t-1} + ... + \theta_q\varepsilon_{t-q} + \varepsilon_t$$`

--

`$$(1 - \phi_1B - ... - \phi_pB^p)(1-B)^dy_t = c + (1 + \theta_1B + ... + \theta_qB^q)\varepsilon_t$$`

- The same invertibility conditions discussed earlier for AR and MA models apply to the respective parts of ARIMA models.

--

- Special cases of ARIMA models previously discussed:
  - White noise = `\(ARIMA(0,0,0)\)` w/o constant
  - Random walk = `\(ARIMA(0,1,0)\)` w/o constant
  - Random walk w/drift = `\(ARIMA(0,1,0)\)` w/constant
  - Autoregressive model = `\(ARIMA(p,0,0)\)` 
  - Moving average model = `\(ARIMA(0,0,q)\)`
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
