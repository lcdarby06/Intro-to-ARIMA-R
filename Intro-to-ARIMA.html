<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to ARIMA Models Using R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Laura Rose" />
    <meta name="date" content="2022-04-19" />
    <script src="libs/header-attrs-2.9/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to ARIMA Models Using R
### Laura Rose
### April 19, 2022

---




## Intro to ARIMA Models
- ARIMA models are one of the most common univariate time series forecasting methods.

--

- ARIMA stands for **A**uto**R**egressive **I**ntegrated **M**oving **A**verage.

--

- We will explore each part of the ARIMA model in detail before moving on to its implementation in R.

---

## For Further Reading
- Hyndman, R.J., &amp; Athanasopoulos, G. (2021) *Forecasting: principles and practice*, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on March 3, 2022.
- Brooks, C. (2008). *Introductory Econometrics for Finance*, 2nd edition, Cambridge University Press: Cambridge, United Kingdom.

---

## Stationarity
- A time series is said to be *strictly stationary* if the distribution of the observations does not change across time.

--

- However, strict stationarity is not always necessary to model a time series. We often reference *weak stationarity* in our analysis.

--

- `\(E(y_{t}) = \mu\)` (constant mean)

--

- `\(E[(y_{t} - \mu)(y_{t} - \mu)] = \sigma^2 &lt; \infty\)` (constant variance)

--

- `\(E[(y_{t_{k}} - \mu)(y_{t_{k'}} - \mu)] = \gamma_{t_{k}-t_{k'}} \space \forall \space t_{k}, t_{k'}\)` (constant autocovariance)

--
  - When `\(k = k'\)`, the autocovariance is the variance.
  
--

- The autocovariance is not particularly useful since it is scale-dependent. Therefore, we often normalize the autocovariance by dividing by the variance.

--

- This is called the *autocorrelation*, and this measure has the usefulness of being bounded between `\(\pm1\)`

---

## White Noise Process

- A *white noise process* is a special case of a stationary process.

--

`$$E(y_{t}) = 0$$`

--

`$$E[(y_{t} - \mu)(y_{t} - \mu)] = \sigma^2$$`

--

`$$\gamma_{k-k'} = \left\{\begin{aligned}
&amp;\sigma^2 &amp;&amp;if \space k = k'\\
&amp;0 &amp;&amp; otherwise
\end{aligned}
\right.$$`

--

- *Note that some definitions of a white noise process indicate a nonzero mean is permissible.*

---

## Random Walk 

- A *random walk* model is often used to denote a nonstationary time series.

--

- `\(y_{t} = y_{t-1} + \varepsilon_{t}\)` or

--

- `\(y_{t} = c + y_{t-1} + \varepsilon_{t}\)` (random walk w/drift)
  - `\(c\)` is the mean of the changes between sequential observations.
  - If `\(c &gt; 0\)`, the mean change will tend towards an increase in `\(y_{t}\)`, and vice versa for negative values of `\(c\)`. 
  
--

- Random walk series often have long period of increases or decreases accompanied with sudden changes in direction.

---

## What to Do If Data is Nonstationary?
- So what happens if we find our data violates any of the (weak) stationarity conditions?

--

- Note that data with trend or seasonality is not stationary, but data with cyclic behavior (i.e., business or other cycles which are not of fixed length) can be stationary.

--

- Differencing the series is a common way to deal with nonstationarity resulting from autocorrelation. 

--

  - The difference of a value with the previous value is called *first-order differencing*: `\(y'_{t} = y_{t} - y_{t-1}\)`.
  - Note that for a random walk model, `\(y'_{t} = \varepsilon_{t}\)`. 
  - Thus, this series is now stationary given the properties of `\(\varepsilon_{t}\)`.
  
--

  - Sometimes this is not enough to make the series stationary, so we take the difference of the differences.

--

`$$\begin{align*}
  y''_{t}  &amp;=  y'_{t}  - y'_{t - 1} \\
           &amp;= (y_t - y_{t-1}) - (y_{t-1}-y_{t-2})\\
           &amp;= y_t - 2y_{t-1} +y_{t-2}
\end{align*}$$`

---

## What to Do if Data is Nonstationary, cont.

- If we notice a seasonal pattern, we can take a seasonal difference: `\(y'_{t} = y_{t} - y_{t-m}\)`, where `\(m\)` is the seasonal period. 

--

- If the data looks like it may require both first-differencing and seasonal differencing, it's better to take the seasonal difference first.

--

- This is especially true in the case of strong seasonality, since sometimes taking a seasonal difference is enough to make the series stationary.

--

- However, taking a first difference will not get rid of seasonal stationarity.

--

- Always use as few differences as possible, since too much differencing can induce patterns in the series that are not actually there.

--

- If the variance appears nonconstant across time, a logarithmic transformation can be used to stabilize.

---

## How to Test for Nonstationarity

- There are both formal and nonformal ways to examine the time series.

--

- We should always start by plotting the time series (line plot is generally best), since often nonstationarity and nonconstant variance are visible to the human eye.

--

- If we suspect nonstationarity, we should plot the autocorrelation function (ACF) and check for observations outside of the 95% confidence interval around 0. We particularly want to examine how quickly these autocorrelations drop to 0.

--

- To formally test for stationarity, we conduct a *unit root test*.

--

- Taking a cue from Dr. Hyndman, we will use the KPSS test, but other tests are available (ADF and PP tests).

--

- A *unit root* implies that the data is essentially a function of its lag(s) where the coefficient equals 1, plus some noise. (There are some variations on this, but we will skip discussion for the sake of simplicity.)
  - In more formal terms, the root of the characteristic equation equals 1.

---

## An Example of Checking for Stationarity

.pull-left[

```r
data(BJsales)
date_sequence &lt;- seq(as.Date("1955-01-01"), 
by = "month", length.out = 150)
Sales_tsib &lt;- tsibble(Month = yearmonth(date_sequence), 
Sales = BJsales, index = Month)
autoplot(Sales_tsib)
```
]

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-1-1.png" width="504" /&gt;
]

---

## Checking the ACF

.pull-left[

```r
Sales_tsib %&gt;% ACF() %&gt;% autoplot()
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-2-1.png" width="504" /&gt;
]

---

## Testing for a Unit Root 


```r
uroot_table &lt;- Sales_tsib %&gt;% 
features(Sales, unitroot_kpss) %&gt;% 
bind_cols(Sales_tsib %&gt;%
features(Sales, unitroot_ndiffs)) %&gt;% 
bind_cols(Sales_tsib %&gt;% 
features(Sales, unitroot_nsdiffs))
knitr::kable(uroot_table, format = "html",
digits = 2, align = "c")
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; kpss_stat &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; kpss_pvalue &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; ndiffs &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; nsdiffs &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 2.62 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.01 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

- We clearly have a unit root (we reject the null hypothesis of stationarity), but it doesn't look like we will need to take a seasonal difference.

---

## Backshift Notation

- This notation is a (hopefully!) helpful shorthand to describe lags of variables for easier manipulation. Think of `\(B\)` as "backshift."

--

- `\(By_{t} = y_{t-1}\)`

--

- By extension, `\(B(By_{t}) = B^2y_{t} = y_{t-2}\)`, etc.

--

- Same quarter last year would be `\(B^4y_{t} = y_{t-4}\)`

--

- We can also use the backshift operator to describe differencing.
`$$y' = y_{t} - y_{t-1} = y_{t} - By_{t} = (1-B)y_{t}$$`
- We can treat the expressions in `\(B\)` like polynomials and solve for roots (thus the unit root concept).
  
--

`$$\begin{align*}
y'' &amp;= (y_{t} - y_{t-1}) - (y_{t-1} - y_{t-2})\\ 
    &amp;= y_{t} - By_{t} - By_{t} + B^2y_{t}\\ 
    &amp;= y_{t} - 2By_{t} + B^2y_{t}\\ 
    &amp;= (B-1)^2y_{t}\\ 
    &amp;= (1-B)^2y_{t}
\end{align*}$$`
  
---

## Autoregressive (AR) Models

- With an AR model, we forecast a time series using a linear combination of prior values of the series. In other words, `\(y_{t}\)` is regressed on itself.

--

- An autoregressive model of order `\(p\)` (an `\(AR(p)\)`) model is written as follows, where `\(\varepsilon_{t}\)` is a white noise process:

--

`$$y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + ... + \phi_{p}y_{t-p} + \varepsilon_{t}$$`
--

- `\(AR(1)\)` models as they relate to previous models we've discussed:
  - when `\(\phi_{1} = 0\)` and `\(c = 0\)`, `\(y_{t}\)` is white noise
  - when `\(\phi_{1} = 1\)` and `\(c = 0\)`, `\(y_{t}\)` is a random walk process
  - when `\(\phi_{1} = 1\)` and `\(c \neq 0\)`, `\(y_{t}\)` is a random walk with drift process
  - when `\(\phi_{1} &lt; 0\)`, `\(y_{t}\)` tends to fluctuate around the mean

--

- `\(AR(p)\)` models, stationary data, and constraints:
  - `\(AR(1)\)` model: `\(-1 &lt; \phi_{1} &lt; 1\)`
  - `\(AR(2)\)` model: `\(-1 &lt; \phi_{2} &lt; 1\)`, `\(\phi_{1} + \phi_{2} &lt; 1\)`, `\(\phi_{1} - \phi_{2} &lt; 1\)`

--

- These restrictions, as well as restrictions for higher orders of `\(p\)`, are handled automatically in the `fable` package.

---

## An Example of AR(1) Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(1, 0, 0),
ar = 0.7), n = 300) %&gt;% as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-3-1.png" width="504" /&gt;
]

---

## Another Example of AR(1)&lt;sup&gt;*&lt;/sup&gt; Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(1, 1, 0),
ar = 0.7), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-4-1.png" width="504" /&gt;
]

.footnote[[*]&lt;small&gt;This is technically not an AR(1) model,&lt;br&gt; but rather an ARIMA(1,1,0).&lt;br&gt; We can see the difference in a stationary versus nonstationary series.&lt;/small&gt;]

---

## An Example of an AR(2) Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(2, 0, 0),
ar = c(1.3, -0.6)), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-5-1.png" width="504" /&gt;
]

---

## Another Example of an AR(2)&lt;sup&gt;*&lt;/sup&gt; Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(2, 1, 0),
ar = c(0.6, 0.3)), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-6-1.png" width="504" /&gt;
]

.footnote[[*]&lt;small&gt;This is technically not an AR(2) model,&lt;br&gt; but rather an ARIMA(2,1,0).&lt;br&gt; We can see the difference in a stationary versus nonstationary series.&lt;/small&gt;]

---

## Moving Average (MA) Models

- The "MA" portion of ARIMA refers to a *moving average* model, where `\(y_{t}\)` is regressed on previous forecast errors. 

--

- `\(y_{t} = c + \varepsilon_{t} + \theta_{1}\varepsilon_{t-1} + ... + \theta_{q}\varepsilon_{t-q}\)`

--

- This is called an `\(MA(q)\)` model, or a moving average model of order `\(q\)`.

--

- Since we don't observe `\(\varepsilon_{t}\)` (the forecast errors are a proxy for `\(\varepsilon_{t}\)`), these models aren't a regression in the sense we normally consider.

--

- `\(\varepsilon_{t}\)` is a white noise process with mean 0 and variance/standard deviation of 1.

---

## An Example of an MA(1) Process

.pull-left[

```r
set.seed(5)
arima.sim(list(order = c(0, 0, 1),
ma = 0.5), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-7-1.png" width="504" /&gt;
]

---

## An Example of an MA(2) Process

.pull-left[


```r
set.seed(5)
arima.sim(list(order = c(0, 0, 2),
ma = c(0.6, 0.3)), n = 300) %&gt;%
as_tsibble() %&gt;%
autoplot(value)
```

]

--

.pull-right[

&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-8-1.png" width="504" /&gt;

]

---

## Invertibility

- We can express any *stationary* `\(AR(p)\)` model as an `\(MA(\infty)\)` model, using backwards substitution. Below is an example for an `\(AR(1)\)` model.

--

`$$\begin{align*}
y_{t} &amp;= \phi_{1}y_{t-1} + \varepsilon_{t}\\ 
    &amp;= \phi_{1}(\phi_{1}y_{t-2} + \varepsilon_{t-1}) + \varepsilon_{t}\\ 
    &amp;= \phi_{1}^2y_{t-2} + \phi_{1}\varepsilon_{t-1} + \varepsilon_{t}\\ 
    &amp;= \phi_{1}^2(\phi_{1}y_{t-3} + \varepsilon_{t-2}) + \phi_{1}\varepsilon_{t-1} + \varepsilon_{t}\\ 
    &amp;= \phi_{1}^3y_{t-3} + \phi_{1}^2\varepsilon_{t-2} + \phi_{1}\varepsilon_{t-1} + \varepsilon_{t}
\end{align*}$$`

--

- When `\(|\phi_{1}| &lt; 1\)`, `\(\phi_{1}^k\)` will approach zero as `\(k \to \infty\)`.
  - `\(y_{t} = \varepsilon_{t} + \phi_{1}\varepsilon_{t-1} + \phi_{1}^2\varepsilon_{t-2} + ...\)`
  
---

## Invertibility, cont.

- An `\(MA(q)\)` process can be inverted to an `\(AR(\infty)\)` process if we impose constraints on the parameters. These constraints are similar to those we saw for `\(AR(p)\)` processes.

--

  - The current forecast error is a function of infinite past and current observations of the time series, as seen for an `\(MA(1)\)` model.
  - `\(\varepsilon_{t} = \sum_{i=0}^\infty(-\theta_{1})^iy_{t-i}\)`

--

  - When `\(|\theta_1| &lt; 1\)`, the impact of observations on the current error declines as we go back in time.
  - If `\(|\theta_1| &gt; 1\)` or `\(|\theta_1| = 1\)`, the distant past observations have more or equal weight to the recent observations, and neither situation makes sense.
  
--

  - So an `\(MA(1)\)` process is invertible when `\(|\theta_1| &lt; 1\)`.

--

  - Similar to an `\(AR(2)\)` process, an `\(MA(2)\)` process is invertible when `\(|\theta_2| &lt; 1\)`, `\(\theta_1 + \theta_2 &gt; -1\)`, `\(\theta_1 - \theta_2 &lt; 1\)`.
  - Other more complex constraints hold for higher orders of `\(q\)`, and the `fable` package handles these.

---

## Putting It All Together

- So far we've discussed `\(AR\)` models, `\(MA\)` models, and differencing time series to ensure stationarity (*I* = *Integration*).

--

- We refer to an `\(ARIMA(p, d, q)\)` model, where `\(p\)` = order of the `\(AR\)` part, `\(d\)` = degree of differencing, and `\(q\)` = order of `\(MA\)` part.

--

`$$y'_t = c + \phi_1y'_{t-1} + ... + \phi_py'_{t-p} + \theta_1\varepsilon_{t-1} + ... + \theta_q\varepsilon_{t-q} + \varepsilon_t$$`

--

`$$(1 - \phi_1B - ... - \phi_pB^p)(1-B)^dy_t = c + (1 + \theta_1B + ... + \theta_qB^q)\varepsilon_t$$`

- The same invertibility conditions discussed earlier for AR and MA models apply to the respective parts of ARIMA models.

--

- Special cases of ARIMA models previously discussed:
  - White noise = `\(ARIMA(0,0,0)\)` w/o constant
  - Random walk = `\(ARIMA(0,1,0)\)` w/o constant
  - Random walk w/drift = `\(ARIMA(0,1,0)\)` w/constant
  - Autoregressive model = `\(ARIMA(p,0,0)\)` 
  - Moving average model = `\(ARIMA(0,0,q)\)`

---

## Implementation of an ARIMA Model in R

.pull-left[

```r
train_data &lt;- Sales_tsib %&gt;% 
filter_index(~ "1966 June") # withhold data for testing
fit &lt;- train_data %&gt;% model(ARIMA(Sales))
```
]

--

.pull-right[

```r
report(fit)
```

```
## Series: Sales 
## Model: ARIMA(1,1,1) 
## 
## Coefficients:
##          ar1      ma1
##       0.8870  -0.6537
## s.e.  0.0627   0.1015
## 
## sigma^2 estimated as 1.878:  log likelihood=-236.72
## AIC=479.44   AICc=479.62   BIC=488.2
```
]

- The `fable` implementation of the Hyndman-Khandakar algorithm selects a model specification based on unit root tests, maximum likelihood estimation, and minimization of the AICc (corrected Akaike Information Criterion which can be a good approximation for cross-validation).
- A stepwise search process is used (unless `stepwise=FALSE` is denoted) so a limited amount of ARIMA models are considered.
- Check out [this link](https://otexts.com/fpp3/arima-r.html) for more info and for details on other arguments.

---

## Residual Review

- It's a good idea to check out the residuals to make sure there is no info contained in the residuals that could be utilized in the model.

--

.pull-left[

```r
ljung.box &lt;- fit %&gt;% augment() %&gt;%
features(.innov, ljung_box, lag = 12, dof = 2)
gg_tsresiduals(fit)
```
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; .model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; lb_stat &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; lb_pvalue &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ARIMA(Sales) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 8.473657 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.5826733 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-9-1.png" width="504" /&gt;

]


- Overall, the residuals look good. There are no values outside of the 95% confidence interval around zero in the ACF plot, although the residuals are not quite normally distributed.

---

## Forecasting with ARIMA Models

- Forecasting is extremely simple with an ARIMA model (and really all models in the `fable` packages).
- You can use English language for the `h` argument, or a number of periods you want to forecast. 
- 80% and 95% intervals are included automatically. Specify `level = NULL` to not show these on the plot.
- Note that to plot both the historical series and the forecast, you need to specify the data as the first argument of `autoplot()`.

--

.pull-left[

```r
fit %&gt;% 
forecast(h = "1 year") %&gt;%
autoplot(Sales_tsib, level=95)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-10-1.png" width="504" /&gt;
]

---

## Checking the Accuracy of Our Model

- When creating a model, measuring prediction/forecast accuracy is key. 
- We withheld data to use for testing our forecast. This is called a *validation set approach*.
- There are other cross-validation approaches, but these are outside of the scope of this presentation.


```r
fcst &lt;- fit %&gt;% forecast(h = "1 year")
fcst %&gt;% accuracy(Sales_tsib) %&gt;% knitr::kable(format = "html", align = "c", digits = 2)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; .model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; .type &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; ME &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; RMSE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; MAE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; MPE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; MAPE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; MASE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; RMSSE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; ACF1 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ARIMA(Sales) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Test &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 3.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.97 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.07 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.36 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.33 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.79 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

- RMSE and MASE are commonly utilized accuracy measures. RMSE (Root Mean Square Error) is in the units of the variable of interest. 
- MASE is a metric that measures how well a forecast performs relative to a naive forecast. A value `\(&lt;1\)` means that the forecast performs better than a naive forecast.

---

## But What If I Want to Specify The Model Myself?

- "Back in my day", we didn't have `fable` to select an ARIMA model for us, so we had to figure it out ourselves.

--

- The traditional way is to rely on the ACF and PACF plots as a starting point.
  - PACF stands for "Partial Autocorrelation Function", and is an autocorrelation function which controls for the effect of `\(y_{t-k}\)` on `\(y_t\)`, removing the effects of lags `\(1...k-1\)` on `\(y_t\)`.
  - The partial autocorrelation for lag `\(k = \phi_k\)`, so it represents the `\(k\)`th (i.e., last) `\(p\)` in an `\(AR(k)\)` model.
  - Thus, we look at the last significant partial autocorrelation to give us an idea of the order of `\(p\)`.

--

- If the data follows an `\(ARIMA(p,d,0)\)` model, then for the **differenced** data:
  - The ACF decays in an exponential or sinusoidal manner.
  - The last significant spike in the PACF is at lag `\(p\)`, with nothing after.
  
--

- If the data follows an `\(ARIMA(0,d,q)\)` model, then for the **differenced** data:
  - The last significant spike on the ACF is at lag `\(q\)`, with nothing after.
  - The PACF decays in an exponential or sinusoidal way.

--

- However, these are not always informative, especially in cases where both `\(p\)` and `\(q\)` are not zero.

---

## Reviewing the PACF and ACF in R

- Consider the sales data we previously modeled.
- We know it is nonstationary and needs to be differenced once.

.pull-left[

```r
train_data %&gt;% 
gg_tsdisplay(difference(Sales), 
plot_type = "partial")
```

- Neither the PACF nor the ACF seem to decay exponentially.

- We could naively go with an `\(ARIMA(2,1,4)\)` model, but this may be too complex.

- It is better to try out both an `\(ARIMA(2,1,0)\)` and `\(ARIMA(0,1,4)\)` first. 
]

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-11-1.png" width="504" /&gt;
]

---

## Model Estimation and Forecasting

.pull-left[

```r
models &lt;- train_data %&gt;% 
model(arima210 = ARIMA(Sales ~ pdq(2,1,0)),
arima014 = ARIMA(Sales ~ pdq(0,1,4)),
arima_auto = ARIMA(Sales))  
models %&gt;% glance() %&gt;% 
arrange(AICc) %&gt;% 
select(.model:BIC) %&gt;% 
knitr::kable(format = "html", align = "c", digits = 2)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; .model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; sigma2 &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; log_lik &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; AIC &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; AICc &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; BIC &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; arima_auto &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.88 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; -236.72 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 479.44 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 479.62 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 488.20 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; arima210 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.93 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; -237.84 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 483.67 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 483.97 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 495.35 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; arima014 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.92 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; -236.80 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 485.60 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 486.25 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 503.12 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

--

.pull-right[

```r
models %&gt;% select(arima_auto) %&gt;% 
gg_tsresiduals()
```

&lt;img src="Intro-to-ARIMA_files/figure-html/resid-display-1.png" width="504" /&gt;
]

---
  
## Summary of Procedures for Modeling an ARIMA Process

.pull-left[
### Automatic Process
- Transform data if necessary to obtain constant variance.
- The `ARIMA()` procedure handles differencing for stationarity and order selection.
- Check residuals from model to ensure they are white noise.
- Produce forecasts from automatically selected model.
]

--

.pull-right[
### Hands-On Process
- Transform data if necessary to obtain constant variance.
- Review data for stationarity (visual inspection, KPSS tests, etc.).
- Review ACF and PACF plots and make some initial model guesses. 
- Compare several reasonable candidate models (including the automatically selected model), and choose the once which minimizes the AICc (or another information criterion). 
- Check the residuals from this model to ensure they are white noise.
- Produce forecasts from the selected model. 
]

---

## The Role of the Constant and Difference in the Model

- We can control whether or not a constant is included in the model by the use of 0 preceding the `pdq(p,d,q)` special. 
- `model(my_arima = ARIMA(my_var ~ 0 + pdq(p,d,q)))` to exclude a constant or `model(my_arima = ARIMA(my_var ~ 1 + pdq(p,d,q)))` to include a constant
- If neither 0 nor 1 is specified, the constant is included depending on if its inclusion minimizes the AICc or not, for `\(d=0\)` or `\(d=1\)`. For `\(d&gt;1\)`, no constant is included. 
- The constant can also affect the long-term forecasts.
- `\(c=0\)`:
  - `\(d=0\)` -&gt; forecasts go to zero.
  - `\(d=1\)` -&gt; forecasts go to a nonzero constant.
  - `\(d=2\)` -&gt; forecasts become a straight line.
- `\(c\neq0\)`:
  - `\(d=0\)` -&gt; forecasts go to mean of data.
  - `\(d=1\)` -&gt; forecasts follow straight line.
  - `\(d=2\)` -&gt; this is not allowed in the `fable::ARIMA()` function, but the forecasts would follow a quadratic trend.
- The degree of `\(d\)` also matters to the long-term forecasts. The greater the value of `\(d\)`, the more quickly prediction intervals increase in size.

---

## How Degree of `\(d\)` Affects Prediction Intervals

.pull-left[

```r
train_data %&gt;% 
gg_tsdisplay(difference(Sales, differences = 2), plot_type = "partial")
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-12-1.png" width="504" /&gt;
- An `ARIMA(0,2,1)` looks reasonable.
]

---

## How Degree of `\(d\)` Affects Prediction Intervals, cont.

.pull-left[

```r
my_models &lt;- train_data %&gt;% 
model(arima111 = ARIMA(Sales ~ pdq(1,1,1)),
arima021 = ARIMA(Sales ~ pdq(0,2,1)))
my_models %&gt;% 
forecast(h = "1 year") %&gt;% 
autoplot(Sales_tsib, level = 95)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-13-1.png" width="504" /&gt;
]

---

## What About Seasonal Models?

- We briefly touched on seasonal ARIMA models earlier in the session.
- It is usually obvious if there is (strong) seasonality in the data, due to spikes at lags on the PACF/ACF plots, as well as patterns in a simple line plot of the data.
- The sales data we previously considered does not have a seasonal pattern, so let's take a look at some seasonal data.
- We will use quarterly tourism data from Australia for the purpose of Holiday.

---

## Modeling Seasonal Data

.pull-left[

```r
h_tourism &lt;- tourism %&gt;% 
group_by(Purpose) %&gt;% 
summarize(Trips = sum(Trips)) %&gt;% 
filter(Purpose == "Holiday") 
h_tourism_train &lt;- h_tourism %&gt;% 
filter_index(. ~ "2016 Q4")
h_tourism %&gt;% 
autoplot(Trips)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-14-1.png" width="504" /&gt;
- Note the slight nonconstant variance; we will need to transform the series prior to modeling.
]

---

## Transforming the Data to Stabilize Variance

.pull-left[

```r
lambda_value &lt;- h_tourism_train %&gt;% 
features(Trips, guerrero) %&gt;% 
pull(lambda_guerrero)
h_tourism %&gt;% 
autoplot(box_cox(Trips, lambda_value))
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-15-1.png" width="504" /&gt;
- This doesn't seem to have done a lot to stabilize the variance, but it may be the best we can do.
- Data is still nonstationary, so we will need to difference.
]

---

## Differencing Seasonal Data

- We will try seasonal differencing first and then see if we also need to first-difference the data.

--


```r
## table for reviewing unit root results
bind_cols(h_tourism_train %&gt;% 
features(Trips, unitroot_nsdiffs),
h_tourism_train %&gt;% 
features(difference(Trips, 4), unitroot_ndiffs) %&gt;%
select(ndiffs)) %&gt;%
knitr::kable(format = "html",
align = "c")
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Purpose &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; nsdiffs &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; ndiffs &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

## Differencing Seasonal Data, cont.

.pull-left[

```r
## adding transformed vars to data set
h_tourism_train &lt;- h_tourism_train %&gt;% 
mutate(Trips_t = box_cox(Trips, lambda_value)) %&gt;% 
mutate(Trips_t_s = difference(Trips_t, 4),
Trips_t_s_d = difference(Trips_t_s, 1))

## visual inspection for stationarity
h_tourism_train %&gt;% 
pivot_longer(-c(Purpose, Quarter),
names_to = 'Variable', values_to = 'Trips') %&gt;% 
mutate(Variable = as.factor(Variable)) %&gt;% 
ggplot(aes(Quarter, Trips)) +
geom_line() +
facet_grid(vars(Variable), scales = 'free_y')
```

```r
h_tourism_train &lt;- h_tourism_train %&gt;% select(-c(Trips_t:Trips_t_s_d)) # removing vars we don't need
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-16-1.png" width="504" /&gt;
]

--

- Visually, there seems to be some stationarity benefit from taking a first difference in addition to the seasonal difference.

---

## Examination of the PACF/ACF Plots

.pull-left[

```r
## note that we are using the transformed, 
## seasonally differenced, and first-differenced variable 
h_tourism_train %&gt;% 
gg_tsdisplay(difference(Trips, 4) %&gt;% difference(), plot_type = "partial", lag_max = 20)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-17-1.png" width="504" /&gt;
]

--

- It looks like there are lag spikes on the ACF plot on lags 1 and 4 and on lags 1, 2, and 4 on the PACF plot. This suggests we try an `\(ARIMA(2,1,1)(1,1,1)_{4}\)` model. 

---

## Seasonal ARIMA Modelling

.pull-left[

```r
seas_mods &lt;- h_tourism_train %&gt;% 
model(arima211111 = 
ARIMA(box_cox(Trips, lambda_value) ~ pdq(2,1,1) + PDQ(1,1,1)), # use the transformed, but not differenced variable since differences specified in formula
auto_arima = ARIMA(box_cox(Trips, lambda_value)))

seas_mods %&gt;% glance() %&gt;% 
arrange(AICc) %&gt;% 
select(.model:BIC) %&gt;% 
knitr::kable(format = 'html', align = 'c',
digits = 2)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; .model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; sigma2 &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; log_lik &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; AIC &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; AICc &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; BIC &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; auto_arima &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 17180.58 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; -450.27 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 906.55 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 906.91 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 913.34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; arima211111 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 16361.26 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; -448.28 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 908.56 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 909.87 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 922.13 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

--

.pull-right[

```r
seas_mods %&gt;% pivot_longer(-Purpose) %&gt;% 
knitr::kable(format = 'html', align='c', digits = 2)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Purpose &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; name &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; arima211111 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; &amp;lt;ARIMA(2,1,1)(1,1,1)[4]&amp;gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; auto_arima &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; &amp;lt;ARIMA(0,1,1)(0,1,1)[4]&amp;gt; &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

- The automatically selected, simpler model has a lower AICc than the model we specified, so we will choose that model.

]

---

## Residual Review for Seasonal Model

.pull-left[

```r
seas_mods %&gt;% select(auto_arima) %&gt;% 
gg_tsresiduals()
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-18-1.png" width="504" /&gt;
]

--

- The residuals look very good, so we are okay to proceed with forecasting.

---

## Forecasting with a Seasonal Model

.pull-left[

```r
h_tourism_train %&gt;% #not using the seas_mods object
#since it makes the back transformations more difficult
model(ARIMA(box_cox(Trips, lambda_value))) %&gt;% 
forecast(h = "1 year") %&gt;% 
autoplot(h_tourism,level = 95)
```
]

--

.pull-right[
&lt;img src="Intro-to-ARIMA_files/figure-html/unnamed-chunk-19-1.png" width="504" /&gt;
]
- The model definitely under-predicts tourism in the winter and spring months (Q3 and Q4). This makes sense given past trends, but this is a case of where a model with external regressors may be helpful in predicting this uptick in travel.

---

## Forecast Accuracy for a Seasonal Model

- The framework is generally the same as with the nonseasonal model. For comparison, we are estimating a seasonal naive model to see if our model outperforms.


```r
h_tourism_train %&gt;% 
model(ARIMA(box_cox(Trips, lambda_value)),
SNAIVE(Trips)) %&gt;%
forecast(h="1 year") %&gt;% 
accuracy(h_tourism) %&gt;% 
select(.model, RMSE, MASE) %&gt;% 
knitr::kable(format = "html", align = "c", digits = 2)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; .model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; RMSE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; MASE &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ARIMA(box_cox(Trips, lambda_value)) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 636.86 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.28 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; SNAIVE(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 681.29 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.46 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

- The accuracy isn't great, but at least it's better than a seasonal naive model.

---

## Estimating Models for Multiple Series

- It's easy in `fable` to estimate models for many time series at once. 
- If we have a `tsibble` with multiple series, and key structure denoted accordingly, `fable` can figure out that we want a separate model(s) for each series.
- Note that for this to work, the data will need to be in long format.


```r
tourism_train &lt;- tourism %&gt;% 
filter_index(. ~ "2016 Q4")

tourism_train %&gt;% 
filter(Purpose == "Holiday") %&gt;% 
model(ARIMA(Trips),
SNAIVE(Trips)) %&gt;% 
forecast(h = "1 year") %&gt;% 
accuracy(tourism) %&gt;% 
select(.model:Purpose, RMSE, MASE) %&gt;% 
arrange(State, Region,Purpose, .model) %&gt;% 
slice_head(n=10) %&gt;% #there are actually 304 series
knitr::kable(format = "html", align = "c", digits = 2)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; .model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Region &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; State &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Purpose &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; RMSE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; MASE &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ARIMA(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Canberra &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; ACT &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 52.04 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.46 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; SNAIVE(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Canberra &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; ACT &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 37.69 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.81 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ARIMA(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Blue Mountains &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; New South Wales &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 44.59 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.62 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; SNAIVE(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Blue Mountains &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; New South Wales &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 35.75 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ARIMA(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Capital Country &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; New South Wales &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 24.64 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.02 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; SNAIVE(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Capital Country &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; New South Wales &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 30.92 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.99 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ARIMA(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Central Coast &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; New South Wales &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 15.31 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.50 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; SNAIVE(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Central Coast &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; New South Wales &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 11.84 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.46 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; ARIMA(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Central NSW &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; New South Wales &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 38.05 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.13 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; SNAIVE(Trips) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Central NSW &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; New South Wales &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; Holiday &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 29.68 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.84 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

- Sometimes the `ARIMA()` model is more accurate than the `SNAIVE()` model, and sometimes not. This also varies depending on metric considered.

---

## Conclusion

- ARIMA models are one of the most commonly used univariate time series methods.
- These models can be useful when:
  - The data are believed to be a function of previous values and/or previous errors.
  - You don't have access to/are unaware of other predictor variables.
- `fable`,`feasts`, and `tsibble` allow you to produce many ARIMA models/forecasts quickly with minimal code, and no use of `purrr`, `for` loops, etc. required.

---

class: center, middle, inverse

# Appendix

---

## Parameter Estimation with `fable`

- Once we have selected the order of the model, the parameter values need to be estimated.
- Maximum Likelihood Estimation (MLE) is commonly used. 
- MLE searches for values of the parameters `\(c\)`, `\(\phi_1....\phi_p\)`, and `\(\theta_1...\theta_q\)` which maximize the probability that the data observed arose from a process with such parameters.
- In the ARIMA context, MLE is similar to least squares (minimizing the sum of the squared residuals).
- Note that when we call `report()` on a `mable` (`fable` model object), we see an entry for *log-likelihood*. 
- This refers to the logarithm of the likelihood that the data come from the estimated model. 
- We want to maximize this value, though AICc (next slide) is more commonly used as a measure of model accuracy.

---

## Information Criteria

- We previously utilized the AICc in comparing models.
- The AICc (Akaike Corrected Information Criterion) is one of several information criteria used to select a good model.
- Note that the `\(y_t\)` variable must be the same to compare between models.
  - We cannot use the AICc or other information criterion to compare between models with different `\(d\)`.
- The AIC (not corrected) is basically -2*log-likelihood + 2 times the number of parameters including `\(\sigma\)`. 
  - The AICc more heavily penalizes for the number of parameters, especially as it relates to the observations in the model. 
- We want to minimize the information criterion (consider the -2 in the equation), so a negative number with a higher magnitude is better.

---

## Prediction Intervals

- As mentioned previously, the width and increase of width of prediction intervals is related to `\(d\)`. 
- In general, prediction interval calculation for ARIMA models is complex, particularly beyond the first period.
  - For the first period, the 95% prediction interval is `\(\hat{y}_{T+1} \pm 1.96\hat{\sigma}\)`, where `\(\hat{\sigma}\)` is the standard deviation of the residuals. Consider that this is because the inputs we have for the model are known, but beyond `\(T+1\)` we have to use forecasted inputs for certain (or all values).
- For an `\(ARIMA(0,0,q)\)` model, the forecast variance at time `\(T+h\)` can be expressed as follows:
`$$\hat{\sigma}^2_h = \hat{\sigma}^2 + \hat{\sigma}^2 \sum_{i=1}^{h-1}\theta^2_i$$` for `\(h&gt;1\)`
- Recall that a stationary `\(AR(p)\)` model can be inverted as an `\(MA(\infty)\)` model, so the equation above shows us a way to calculate intervals for stationary `\(AR(p)\)` models.

  


  
  
  
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
